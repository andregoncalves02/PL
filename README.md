# Introduction
As part of the Language Processing course, we were presented with various problem/challenge statements, from which we had to select one to solve. Therefore, we thought that the most interesting one would be the Pug to HTML(2.5) converter. Despite being two relatively similar languages, they have some differences that were challenging to implement. For this, we used the Python programming language and the Ply library, which provides us with ply.lex and ply.yacc tools. Using these, we created a lexer and a parser.

Pug is a simplified markup language that allows writing HTML in a more concise and indented manner, while HTML is the standard language for structuring and displaying content on the web. Implementing a converter between these languages involves dealing with the nuances of each and transforming Pug code into valid HTML.

The use of the Ply library in Python to create the lexer (lexical analyzer) and parser (syntax analyzer) facilitates the analysis and transformation of Pug code into its equivalent representation in HTML. The lexer tokenizes the source code into smaller chunks, while the parser interprets the syntactic structure of these tokens to generate the desired output in HTML.

This project likely involved identifying and manipulating specific elements of Pug, such as significant indentation, abbreviations, and other unique characteristics, to produce semantically correct and structured HTML code.
# PUG -> HTML converter
As mentioned earlier, Pug and HTML are two relatively similar languages, with some differences that can be challenging to implement. Therefore, to develop this program, it was necessary to create a token lexer to identify the tokens present in the Pug language and assign a name to each one. This was done to later determine how to handle each token in the parser. Additionally, a structure was created from these tokens that would make sense in the HTML language without altering the meaning it had in Pug.

To accomplish this, we created a lexer to break down the various tokens and a parser to build our HTML language. The tools used for this purpose were ply.lex for the lexer and ply.yacc for the parser.

The lexer's role was to tokenize the input code, breaking it down into smaller units (tokens) representing various elements of the Pug language. Meanwhile, the parser interpreted the sequence of tokens generated by the lexer and constructed a structured representation of HTML while preserving the semantics and meaning from the original Pug code.

This process aimed to ensure that the conversion from Pug to HTML was accurate and that the resulting HTML maintained the intended structure and functionality of the original Pug code.
# Lexer

To build a Lexer in Python, it's necessary, initially, to define which tokens need to be captured and the various states these tokens could enter. Thus, several tokens and states needed to be defined.

We began by defining the necessary tokens. However, it was necessary to create states for some of these tokens because certain tokens could have different formats in various cases. Both states were exclusive to ensure that the rules of the initial state didn't interfere with the rules of the particular state itself.
# Parser

Once all the tokens present in the code that we want to convert are identified, it's necessary to organize these tokens to build a language that makes sense in HTML. For this purpose, we utilized a tool from the Ply library in Python called yacc. This parser will analyze the received text and recursively (Bottom-up) use the defined tokens to build meaningful phrases. To achieve this, it was necessary to define multiple functions that organize the tokens as required.
